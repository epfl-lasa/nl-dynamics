 <launch>

 	<!-- No need to roscore if we use a launchfile -->
 	<!-- type correspond to node name -->	
 	<!--
      Launch file for the speech recognizer (with the manipulator command
      language model and ROS audio message subscription), and optionally the
      microphone capture.

      Usage:
      roslaunch pocketsphinx robot_voice_control.launch

      Usage (no microphone):
      roslaunch pocketsphinx robot_voice_control.launch microphone:=0
  	-->
	<arg name="microphone" default="1"/>  <!-- optional -->
	<node name="microphone_capture" pkg="audio_capture" type="audio_capture" 		
			if="$(arg microphone)">
		<param name="bitrate" value="128"/>
	</node>


	<!-- subscribe to /audio ROS messages -->
	<node name="recognizer" pkg="pocketsphinx" type="recognizer.py">
		<param name="lm" value="$(find controller_demonstrations)/language_models/robot_control.lm" />
		<param name="dict" value="$(find controller_demonstrations)/language_models/robot_control.dic" />
		<param name="audio_msg_topic" value="/audio" />
		<remap from="~output" to="nl_command_parsed"/>
	</node>

	<node name ="sound_play" pkg="sound_play" type="soundplay_node.py"/>

	<node name ="demo" pkg="controller_demonstrations" type="interactive_demo.py" output="screen"
	required="true"/>

	<node name ="smach_viewer" pkg="smach_viewer" type="smach_viewer.py" output="screen"/>


  </launch>